{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통계 모델링과 머신 러닝 모델링은 방식은 서로 다르지만 해결하려는 과제는 같다. \n",
    "\n",
    "# 선형회귀모형\n",
    " - 통계 모델링\n",
    "  - 선형회귀 모델은 초평면과 관측값 사이의 오차를 최소화하는 방법으로 최적 hyperplane을 fitting한다. \n",
    "  - 통계 모델은 신뢰성 검증을 위해 다중공선성(multi-collinearity) 검사를 해야 한다.\n",
    "  - 훈련 집합에 관해 이중 검증, 즉 모델의 정확도 테스트와 개별 매개변수의 유의성 테스트를 모두 수행한다. 선형이나 로지스틱 회귀는 모델 자체의 형태상 낮은 분산을 가지므로 처음 보는(unseen) 데이터에 관해 성능 차이가 크게 달라질 확률은 아주 낮다.\n",
    " - 머신 러닝 모델링\n",
    "  - 같은 문제를 최적화 문제로 변환한다. 즉, 오차를 제곱한 형태로 모델링을 한 후 모수에 관한 최적화를 통하여 오차를 최소해 나간다. \n",
    "  - 다중공선선 문제를 보상하기 위해 모수에 대한 값을 스스로 조정한다. 특히 Bagging, Random forest, Boosting과 같은 트리 기반의 ensemble 모델은 다중공선성 문제가 존재하지도 않는다.\n",
    "  - 모델이 고도의 유연성을 가지므로 아주 심한 변화가 가능하며, 개별 변수 단위의 통계 진단은 머신 러닝에서 수행할 수 없다.\n",
    "  - Overfitting을 피하기 위해 안정성이 보장돼야 구현 단계에서도 처음 보는 데이터에 관해 올바르게 작동하리라는 것을 보장 할 수 있다.\n",
    "  - 데이터를 훈련/검증/테스트 세트로 나눈 후, 훈련 데이터를 이용하여 모델을 개발하고, hyperparameter는 검증 데이터를 사용해 튜닝한다. 이것은 통계 모델에서의 이중 진단과 같은 효과를 내며 개별 변수 단위의 진단을 수행하지 않고도 모델의 안정성을 보장할 수 있게 해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀의 가정\n",
    " - 종속 변수는 독립 변수의 선형 조합이어야 한다.\n",
    "  - $y=\\beta_0 + \\beta_1 \\times x_1 + \\beta_2 \\times x_2^2$에서 $x^2$은 이차항이지만, 변수간의 선형 조합이라는 가정을 충족시킨다.\n",
    " - Error terms(오차항)에 autocorrelation(자기상관관계)가 없어야 한다.\n",
    "  - 오차항의 상관관계는 모델의 정확성을 훼손시킨다.\n",
    "  - 진단 방법 : 더빈 왓슨 검정(Durbin-Watson test)을 사용한다. 더빈 왓슨의 $d$ 검정은 '잔차에는 선형 자기 상관관계가 없다'라는 귀무가설을 검정한다. $d$는 0과 4중 어느 값을 갖는데, $d$가 2에 가까우면 자기 상관관계가 없다는 것을 의미하고, $0<d<2$일 경우 양의 자기 상관관계, $2<d<4$인 경우 음의 자기상관관계를 나타낸다.\n",
    " - <font color=red>오차는 평균이 0이면서 정규분포를 따라야 한다.</font>\n",
    "  - 모델이 편향되지 않은 계산을 하려면 오차항의 평균이 0이어야 한다. 오차의 분포를 Q-Q그림을 이용하여 살펴볼 수 있다. 오차 항이 정규분포를 따르지 않으면 신뢰 구간이 너무 넓어지거나 좁아지므로 최소 자승법에 의한 최소화 계수 계산이 어려워진다. \n",
    "  - 진단 방법 : Q-Q 도표와 Kolmogorov-Smirnov(콜모고로프-스미노프) 검정을 사용한다.\n",
    " - Multi-collinearity(다중공선성)은 존재하지 않거나 거의 없어야 한다.\n",
    "  - 다중공선성은 독립 변수끼리 서로 상관관계를 가져 계수나 계산값을 부풀리므로 모델의 신뢰도를 떨어뜨린다. 또 결과값에 어느 변수가 얼마나 기여했는지 판단하기 힘들다. 전체 독립 변수에 관한 개별 독립 변수의 $R^2$를 계산하는 방식으로 각 독립 변수의 Variance Inflation Factor(VIF)를 계산하고 가장 높은 VIF 값을 가진 변수를 하나씩 제거해 나가야 한다. $VIF=\\frac{1}{1-R^2}$\n",
    "  - 진단 방법 : 데이터의 모든 변수에 상관관계 계수를 적용하고 산포도를 살펴본다.VIF를 계산해서 $VIF \\leq 4$이면 다중공선성이 없다는 것을 의미하는데, 은행의 경우 $VIF \\leq 2$를 사용하기도 한다.\n",
    " - Error terms는 homoscedastic(등분산성)을 가져야 한다.\n",
    "  - 오차는 독립 변수들에 관해 일정한 분산값을 가져야 한다. 그렇지 않으면 비현실적으로 넓거나 좁은 신뢰 구간이 형성되고 모델의 성능을 떨어뜨리게 된다. 등분산성을 깨뜨리는 원인 중 하나는 데이터의 이상값으로 자기 쪽으로 모델의 parameter 값이 높은 가중치를 갖도록 모델이 fitting 될 때 영향을 끼친다.\n",
    "  - 진단 방법 : 잔차와 독립 변수의 산포도를 살펴본다. 큰 모양이나 발산이 존재하면 오차가 일정한 분산을 갖지 않는다는 것을 의미하고 예측에 영향을 미치게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 선형회귀분석에서 종속변수가 시간 또는 위치에 영향을 받는 시계열데이터인 경우 이웃하는 관찰값들 사이에 상관관계가 있을 수 있음\n",
    "\n",
    "- 따라서 이러한 데이터 set에서는 오차항들이 서로 독립적이라는 조건을 검토해보아야 함\n",
    "\n",
    "- 이러한 상관을 자기상관(autocorrelated)이라고 하며, 자기상관은 한 시점의 오차항과 과거시점들의 오차항들과의 상관임\n",
    "\n",
    "- 자기상관(독립성)을 알아보기 위해 주로 Durbin-Waston 통계량을 사용\n",
    "\n",
    "\n",
    "\n",
    ". 오차(error)의 정의\n",
    "\n",
    "- 모집단에서 실제값이 회귀선과 비교해 볼 때 나타나는 차이(정확치와 관측치의 차이)\n",
    "\n",
    "\n",
    ". 잔차의 정의\n",
    "\n",
    " \n",
    "\n",
    "- 표본에서 나온 관측값이 회귀선과 비교해볼 때 나타나는 차이\n",
    "\n",
    "- 회귀모형에서 오차항은 측정할 수 없으므로 잔차를 오차항의 관찰값으로 해석하여 오차항에 대한 가정들의 성립 여부를 조사함\n",
    "\n",
    "\n",
    "\n",
    "위의 2개의 그래프에서 왼쪽에 있는 모형은 모집단의 모수식을 표현한 것이다. 즉, 우리가 궁극적으로 알고자 하는 실제의 식인 것이다. 이 경우, 모든 data 들(점)을 하나의 회귀식으로 100% 설명할 수 없다. 그래서 생각해 낸 것이 바로 오차(error) 라고 하는 것으로, 이 값은 회귀식의 값과 실제값과의 차이를 말한다. \n",
    "여기에서는 어떤 하나의 점과 회귀식과의 차이를 표현한 입실론(epsilon)이 바로 오차이다.\n",
    "\n",
    "이에 비해서 잔차(resudial)라고 하는 것은 표본의 회귀식에 나온 값이다. 표본에서도 마찬가지로 회귀식을 구할 수 있다. 그러나, 그 회귀식은 모집단의 실제 회귀식과는 차이가 있을 수 있다. 이때에 모집단의 회귀식과 마찬가지로 표본의 회귀식에서도 잔차라는 것을 생각할 수 있으며, 같은 아이디어에 의해 구해지게 된다. \n",
    "그러나, 오차는 모수의 개념이므로 표본에서는 오차라는 용어대신 통계량의 개념을 갖는 잔차(error)라는 용어로 대신 부르게 된다.\n",
    "\n",
    "결국, 오차와 잔차는 같은 개념이지만 모집단의 값인가, 표본의 값인가에 따라 서로 달리 부르게 되는 것이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 선형 회귀 모델링 단계 (통계적 모델링)\n",
    " 1. 결측값(missing value), 이상값(outlier)를 처리한다.\n",
    " 2. 독립 변수 간의 상관 관계를 확인한다.\n",
    " 3. 훈련 데이터와 테스트 데이터를 나눈다.\n",
    " 4. 훈련 데이터를 이용하여 모델을 fitting\n",
    " 5. 테스트 데이터를 사용해 모델을 평가\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
